{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Text Extraction \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted, cleaned, and saved as '/Users/paria/Desktop/equity/LitExtract/alltext/The Use of Artificial Intelligence with Students with Identified Disabilities  A Systematic Review with Critique.txt'.\n",
      "Text extracted, cleaned, and saved as '/Users/paria/Desktop/equity/LitExtract/alltext/WilsonFutureEng.txt'.\n",
      "Text extracted, cleaned, and saved as '/Users/paria/Desktop/equity/LitExtract/alltext/literature-review-on-disability-participation-in-the-engineering-field.txt'.\n",
      "Text extracted, cleaned, and saved as '/Users/paria/Desktop/equity/LitExtract/alltext/missing-from-the-classroom-current-representations-of-disability-in-engineering-education.txt'.\n",
      "Text extracted, cleaned, and saved as '/Users/paria/Desktop/equity/LitExtract/alltext/Intelligent Tutoring System in Education for Disabled Learners Using Human Computer Interaction and Augmented Reality .txt'.\n",
      "Text extracted, cleaned, and saved as '/Users/paria/Desktop/equity/LitExtract/alltext/ChatBot4AgingCogDis.txt'.\n",
      "Text extracted, cleaned, and saved as '/Users/paria/Desktop/equity/LitExtract/alltext/004_Alexa.txt'.\n",
      "Text extracted, cleaned, and saved as '/Users/paria/Desktop/equity/LitExtract/alltext/Exploring student disability and professional identity  navigating sociocultural expectations in U.S. undergraduate civil engineering programs.txt'.\n",
      "Text extracted, cleaned, and saved as '/Users/paria/Desktop/equity/LitExtract/alltext/frobt-09-1006921.txt'.\n",
      "Text extraction and saving complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdfminer.high_level import extract_text\n",
    "import codecs\n",
    "\n",
    "def extract_text_from_pdf(pdf_filename, txt_filename):\n",
    "    try:\n",
    "        # Extract raw text from the PDF\n",
    "        raw_text = extract_text(pdf_filename)\n",
    "\n",
    "        # Use UTF-8 encoding to decode the text (assuming UTF-8 is common)\n",
    "        decoded_text = raw_text.encode('utf-8', 'ignore').decode('utf-8')\n",
    "\n",
    "        # Clean the text by removing extra spaces and non-breaking spaces\n",
    "        cleaned_text = ' '.join(decoded_text.split())\n",
    "\n",
    "        # Save the cleaned text to the specified text file\n",
    "        with codecs.open(txt_filename, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            txt_file.write(cleaned_text)\n",
    "\n",
    "        print(f\"Text extracted, cleaned, and saved as '{txt_filename}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Create the 'alltext' folder if it doesn't exist\n",
    "alltext_directory = os.path.join(current_directory, 'alltext')\n",
    "os.makedirs(alltext_directory, exist_ok=True)\n",
    "\n",
    "# Specify the directory containing the PDF files\n",
    "pdf_directory = os.path.join(current_directory, 'pdfs')\n",
    "\n",
    "# Iterate through the PDF files in the 'pdfs' directory\n",
    "for pdf_file in os.listdir(pdf_directory):\n",
    "    if pdf_file.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(pdf_directory, pdf_file)\n",
    "\n",
    "        # Create a text file with the same name as the PDF (minus the \".pdf\" extension) in 'alltext' folder\n",
    "        text_filename = os.path.splitext(pdf_file)[0] + '.txt'\n",
    "        text_file_path = os.path.join(alltext_directory, text_filename)\n",
    "\n",
    "        # Extract and clean text from the PDF file using the defined function\n",
    "        extract_text_from_pdf(pdf_path, text_file_path)\n",
    "\n",
    "print(\"Text extraction and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Method Section Extreaction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/paria/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant sentences from 'alltext/literature-review-on-disability-participation-in-the-engineering-field.txt' saved in 'methods/literature-review-on-disability-participation-in-the-engineering-field.txt'.\n",
      "Relevant sentences from 'alltext/missing-from-the-classroom-current-representations-of-disability-in-engineering-education.txt' saved in 'methods/missing-from-the-classroom-current-representations-of-disability-in-engineering-education.txt'.\n",
      "Relevant sentences from 'alltext/The Use of Artificial Intelligence with Students with Identified Disabilities  A Systematic Review with Critique.txt' saved in 'methods/The Use of Artificial Intelligence with Students with Identified Disabilities  A Systematic Review with Critique.txt'.\n",
      "Relevant sentences from 'alltext/WilsonFutureEng.txt' saved in 'methods/WilsonFutureEng.txt'.\n",
      "Relevant sentences from 'alltext/004_Alexa.txt' saved in 'methods/004_Alexa.txt'.\n",
      "Relevant sentences from 'alltext/Exploring student disability and professional identity  navigating sociocultural expectations in U.S. undergraduate civil engineering programs.txt' saved in 'methods/Exploring student disability and professional identity  navigating sociocultural expectations in U.S. undergraduate civil engineering programs.txt'.\n",
      "Relevant sentences from 'alltext/frobt-09-1006921.txt' saved in 'methods/frobt-09-1006921.txt'.\n",
      "Relevant sentences from 'alltext/Intelligent Tutoring System in Education for Disabled Learners Using Human Computer Interaction and Augmented Reality .txt' saved in 'methods/Intelligent Tutoring System in Education for Disabled Learners Using Human Computer Interaction and Augmented Reality .txt'.\n",
      "Relevant sentences from 'alltext/ChatBot4AgingCogDis.txt' saved in 'methods/ChatBot4AgingCogDis.txt'.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the input folder and output folder\n",
    "input_folder = 'alltext'\n",
    "output_folder = 'methods'\n",
    "\n",
    "def extract_and_generate_sentences(input_filename, output_filename):\n",
    "    try:\n",
    "        with open(input_filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Tokenize the text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        # Initialize a list to store cleaned and relevant sentences\n",
    "        relevant_sentences = []\n",
    "\n",
    "        # Define keywords to search for\n",
    "        keywords = [\"experiment\", \"survey\", \"interview\"]\n",
    "\n",
    "        # Define a function to clean up a sentence\n",
    "        def clean_sentence(sentence):\n",
    "            # Remove leading/trailing whitespace and extra spaces\n",
    "            cleaned_sentence = ' '.join(sentence.split())\n",
    "            return cleaned_sentence\n",
    "\n",
    "        # Iterate through the sentences to find relevant sentences\n",
    "        for sentence in sentences:\n",
    "            for keyword in keywords:\n",
    "                if keyword in sentence.lower():\n",
    "                    cleaned_sentence = clean_sentence(re.sub(r'\\b' + re.escape(keyword) + r'\\b', '', sentence, flags=re.I))\n",
    "                    if cleaned_sentence:  # Check if the cleaned sentence is not empty\n",
    "                        relevant_sentences.append(f\"{keyword.capitalize()}: {cleaned_sentence}\")\n",
    "\n",
    "        # Generate the output text\n",
    "        output_text = \"\\n\".join(relevant_sentences)\n",
    "\n",
    "        # Construct the output file path in the \"methods\" folder with the same filename\n",
    "        output_file_path = os.path.join(output_folder, os.path.basename(output_filename))\n",
    "\n",
    "        # Save the output text to the specified file\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "            output_file.write(output_text)\n",
    "\n",
    "        print(f\"Relevant sentences from '{input_filename}' saved in '{output_file_path}'.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {input_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create the \"methods\" folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get a list of all text files in the input folder\n",
    "    input_files = [f for f in os.listdir(input_folder) if f.endswith('.txt')]\n",
    "\n",
    "    for input_file in input_files:\n",
    "        input_filename = os.path.join(input_folder, input_file)\n",
    "        output_filename = os.path.join(output_folder, input_file)\n",
    "        extract_and_generate_sentences(input_filename, output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
