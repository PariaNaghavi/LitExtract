Computers in the Schools Interdisciplinary Journal of Practice, Theory, and Applied Research ISSN: (Print) (Online) Journal homepage: https://www.tandfonline.com/loi/wcis20 The Use of Artificial Intelligence with Students with Identified Disabilities: A Systematic Review with Critique Mary F. Rice & Shernette Dunn To cite this article: Mary F. Rice & Shernette Dunn (02 Sep 2023): The Use of Artificial Intelligence with Students with Identified Disabilities: A Systematic Review with Critique, Computers in the Schools, DOI: 10.1080/07380569.2023.2244935 To link to this article: https://doi.org/10.1080/07380569.2023.2244935 Published online: 02 Sep 2023. Submit your article to this journal Article views: 98 View related articles View Crossmark data Full Terms & Conditions of access and use can be found at https://www.tandfonline.com/action/journalInformation?journalCode=wcis20 Computers in the sChools https://doi.org/10.1080/07380569.2023.2244935 The Use of Artificial Intelligence with Students with Identified Disabilities: A Systematic Review with Critique Mary F. Ricea and Shernette Dunnb auniversity of new mexico, Albuquerque, new mexico, usA; bthe united states Air Force Academy preparatory school, Colorado, usA ABSTRACT While Artificial Intelligence (AI) is emerging as assistive technol- ogy for students with identified disabilities there is a need to understand the present literature and set new directions for future study. There is also a need to consider how students that have been identified with disabilities and their families might be positioned by technologies that are supposed to facilitate educa- tional processes. The purpose of this review was to identify rele- vant studies and determine their characteristics as well as describe the positions and orientations to these young people and their families. Moving into 2023, the research base was slim, yet there were troubling patterns emerging in how AI was posi- tioned in the context of relieving the burden of working with young people identified with disabilities, rather than empower- ing young people and their families. Recommendations for future research and research practices are shared. KEYWORDS Artificial intelligence in special education; artificial intelligence for students with disabilities; artificial intelligence and learner support; critical framing of students with disabilities Assistive technologies have increased in sophistication over time in their abilities to support learning processes (Edyburn, 2004, 2013). One emergent type of assistive technologies is Artificial Intelligence (AI). In AI, complex computerized, automated systems engage the human-attributed actions of analyzing, synthesizing, adapting, and even learning (Becker, 2017; Luckin et al., 2016; Popenici & Kerr, 2017). Recently more attention has been paid to AI and its possibilities for supporting young people who have been formally identified with disabilities and who are receiving special education services (Catlin & Blamires, 2019). Studies of AI in special education are estimated to have increased in the last 30 years, leading up to the COVID-19 pandemic (Luckin et al., 2016). Educational uses of AI have touted the goal of providing a personalized learning experience (Karsenti, 2019). Personalized learning is supposed to be tailored to knowledge, interests, and learners’ present abilities (Brown et al., 2020; Vincent-Lancrin & Van der Vlies, 2020). For example, CONTACT mary F. rice © 2023 taylor & Francis Group, llC maryrice@unm.edu university of new mexico, Albuquerque, nm, usA. 2 M. F. RICE AND S. DUNN AI robots that model skills and respond to learners have been developed for supporting a variety of subject matter including mathematics, reading, and computer programming (Chassignol et al., 2018). Other AI applications may supplement teacher work for tasks like assessment and grading (Fahimirad & Kotamjani, 2018; Vincent-Lancrin & Van der Vlies, 2020). Because of differences in their development and experiences, support needs of parents or caregivers, and legislative protections in some countries, young people deserve specific consideration in this type of research (Rice et al., 2019). Moreover, critical readings of AI research for children with disabilities is necessary due to the historical exploitation of individuals with disabilities, the denial of equal educational opportunities for these children, and the fre- quent depictions of them as burdens in educational settings (Rice & Ortiz, 2022; Dobusch, 2017; Lalvani & Broderick, 2013). Acknowledging how indi- viduals identified as having disabilities are framed in the research studies about them is important for understanding research about this population. While individuals deserve access to civil rights in the form of accommodations and services that come with having a condition recognized as a disability (Kenny et al., 2016), it is also important to recognize how social contexts enable and dis/able (Dunn & Andrews, 2015; Goodley et al., 2019; Sinclair, 2013). Nuanced language regarding who is labeled as having disability in education and in research makes the difference between research that are acts of advocacy and ones that further stigmatize (Mertens & Ginsberg, 2008). Considering this context, we sought to undertake a systematic review of literature focused on AI use for school-aged children (Kindergarten through grade 12) that had been or would be identified as having various types of disabilities. We identified patterns and trends in the findings of these studies that drew attention to how those with disabilities were framed as agents (or not) to justify the need for AI technologies and services. Our specific research questions were: 1. Who are the participants in AI research conducted with school-aged youth? 2. What are the stated intentions for supporting this population with AI? 3. What are findings of these studies about AI as a support for young people who have been identified with disabilities? 4. How are disabilities framed and discussed in justifying the need for the AI support? Literature review methods This study used systematic review methods to reveal the research trends on this topic. According to the Cochrane Handbook (Higgins et al., 2019), systematic reviews enable readers to access up-to-date and complete CoMpUTERS IN ThE SChoolS 3 information on all available research evidence. Higgins et al. (2019) also added that a systematic review can identify gaps, limitations, deficiencies, and any lack of evidence in the literature. One of the major outcomes of a strong review is to present the state of current research to open space for future research. Our review aimed to reveal research trends in AI as support for students identified with disabilities between 2009 and 2022. Those dates were selected to capture the most current research with a sufficient 10-year lead time coming into the COVID-19 pandemic years. AI is a fast-moving area of development in education, with new types of AI and new uses emerging regularly. Due to this speed of development that it is important to capture the state of AI for specific populations at specific times. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) checklist was used as primary guidance for identifying articles for this work (Moher et al., 2009). Data collection Searched databased included: SCOPUS, EBSCO, ERIC, CORE Scholar, SCI-Expanded, SSCI, ThinkIR, TR Dizin using Boolean combinations of terms from disability, AI, and age ranges to ensure studies focused on young people. Specific terms appear in Table 1. Searches were conducted for publications published from January 2009 to December 2022. The search criteria returned 177 publications from the databases. After removing duplicates there were 109 remaining. Figure 1 provides an overview of this process. All 109 studies were reviewed by keywords and abstract, resulting in the removal of an additional 91 studies. Studies were removed because they (a) were about adults despite search operators; (b) focused on the entire lifespan rather than having a specific focus on young learners; (c) were not published in peer-reviewed journals; (c) were dissertations or published in conference proceedings; and/or (d) they were theoretical work rather than empirical studies with participants. Close readings of the Ai terms Age range terms Artificial intelligence Chat bot smart tutoring expert systems Adolescents Children schoolchildren Youth Table 1. search terms. Disability terms Autism spectrum Disorder Blindness Cognitive disability Dyslexia intellectual disability language and learning disability mobility disability multiple disabilities orthopedic impairment specific earning disabilities Visual impairment special education 4 M. F. RICE AND S. DUNN Figure 1. overview of the search and exclusion process. 17 remaining studies were used to build a table that captured participant information, study site information, research purposes and designs, find- ings, and evidence from texts about the orientation to disability and its relationship to the need for AI research. The next step was to search the reference sections and bibliographies of included articles to determine whether additional articles were available. Through this bibliographic search, 1 additional study was identified that was not already in the research data set. During the exclusion process, it appeared that researchers conducting studies about AI focused on children with disabilities to date have been citing studies from higher education, work with adults, theoretical work, and research about the benefits and possibilities of assistive technologies in general. Also, where there a few studies with AI robots that focused on the perception or acceptance of the robot rather than the way in which AI was used to support the young person. These were not part of our review criteria and were excluded. Data analysis The full text of 18 articles was examined. Per Higgins et al. (2019), to avoid errors, mined data from the articles were coded separately by the two researchers and both code sets were compared. Cohen’s Kappa coefficient value was cal- culated to measure inter-rater reliability. Cohen’s Kappa was 0.95, which can be interpreted as strong agreement (0.81–1.00) (McHugh, 2012). Tabulation of some data, such as the countries where the studies originated was straightfor- ward, but examining the positioning of disability, the participants, and AI required different analysis (van Dijk, 1998). CoMpUTERS IN ThE SChoolS 5 For RQ 4, we worked to link words and phrases directly from the article text to overall speech acts (Fairclough, 2003; Wodak & Meyer, 2016). For example, Tafla et al. (2021) noted that individuals were “diagnosed” (p. 10) with having an intellectual disability—a term common in disability research but associated with pathology. The term diagnosis suggests that a disability is not a neutral condition. Another example is Soykan et al. (2017) who retained the term “mentally retarded” (p. 2) in their work even though that term is considered offensive in most disability advocacy settings. A third example is from Chung (2019) who made the blanket statement, “children with ASD like robots” (p. 430). Harré et al. (2003) definition of position as “a loose set of rights and duties that limit possibilities for action” (p. 5). We also used concepts of narrativity and agency from Bal and Lewin (1983) and Bal and Van Boheemen (2009) for the analysis. In this type of narratology, characters are positioned as people who have things done to them, actors do things, and narrators tell stories. These terms helped us make sense of the phrases by giving us tools for thinking about who was telling the story of the research, who was doing what to whom, and what the actions revealed about power and position. We made evaluations of disability positioning or framing and shared these with each other during two meeting sessions. During the analysis, we considered how the language used in the studies described the social positioning of individuals as well as the AI that was supposed to support them. We worked through language samples we had extracted from the articles until we agreed on positions and orientations for the 18 articles. Findings This section contains the findings of 18 studies in alignment with the questions posed by the review. The section contains information about (1) types of disabilities, (2) other demographic characteristics, and (3) presence of parents and teachers. Table 2 provides a study-by-study infor- mation from this review. Note that we classified the disabilities according to how the researchers in the studies did, regardless of whether they aligned with the search terms in our review. RQ1: Who are the participants in AI research conducted with school-aged youth? Types of identified disabilities Participants in the studies represented a diverse group from across the globe with varying skills, interests, and backgrounds in AI technologies. Disability identifications represented included Autism Spectrum Disorder (4 studies); intellectual disabilities (3 studies); languages and learning 6 M. F. RICE AND S. DUNN n o i t a c u d e l a i c e p s h t i w d e t a i c o s s a a t a d f o s t n u o m a e g r a l d e g a n a m . s n o i t n e v r e t n i . s n o i s i c e d d e m r o f n i t r o p p u s d n a a t a d s s e r g o r p y l i a d e z y l a n a d n a t c e l l o c o t d e d e e n e m i t ) D D ( s e i t i l i b a s i D ) c a r t D D ( m e t s y s e c n e g i l l e t n i e v i t c e l l o C e c u d e r o t ) c a r t D D ( n o i t a c i l p p a d e s a b - b e w a e t a e r C l a t n e m p o e v e D l d n a , s r o t a r t s i n m d a i s r o t a c u d e l o o h c s , s e t a t s 4 n i s t n e d u t s 5 7 2 s u ) 9 0 0 2 ( g g e r G h t i w D l f o % 0 5 o t p u d e fi i t n e d i t n e r r u c ( s e i t i l i b a s i d i g n n r a e l r o f s s e s s a . e c n e d fi n o c % 0 0 1 . ) % 0 5 < l e v e l e c n e d fi n o c ) D l ( h g h i d n a y r a t n e m e l e . s t n e d u t s l o o h c s i i n m u l ) 9 0 0 2 ( s r e h c r a e s e r . d e c u d e r r o r r e n a m u h o t d e s u i s e u q n h c e t d r a d n a t s f o y c a r u c c a e s a e r c n i s e i t i l i b a s i D i g n n r a e l m o r f i d e n a t b o t e s a t a D y l a t i d n a i n n a n . s l l i k s l a i c o s d n a y c a c ffi e - f l e s d n a t n e m y o n e j , . e . i ( e c n e i r e p x e ’ s r e s u n o i g n n r a e l 4 1 - 3 1 ) 9 0 0 2 ( o t d e t u b i r t n o c m e t s y s a m a r d - e s r a t a v a D 3 r o D 2 g n i s u f o s s e n e v i t c e ff e i e n m a x e d n a e g a u g n a l d e g a s t n e c s e o d a l 0 2 m o d g n K i d e t i n u . l a t e g n a h Z ) e c n e s e r p ) D l l ( s e i t i l i b a s i D s t n e d u t s n i d e s a e r c n i y r o m e m g n i k r o W s t n e d u t s r o f y t i c a p a c y r o m e m g n i k r o w e s a e r c n i l a u t c e l l e t n i d e g a s t n e c s e o d a l 2 1 n a r i . l a t e n a i r a v a l e D i d e d v o r p n e h w D i h t i w d e fi i t n e d i e c a f r e t n i r e t u p m o c - n a m u h h t i w D i h t i w ) D i ( s e i t i l i b a s i D 4 1 - 9 ) 5 1 0 2 ( i s g n d n F i ) s ( e s o p r u p h c r a e s e r ) s e i ( t i l i b a s i D s t n a p i c i t r a p s e t i s r a e Y & r o h t u A i . s e d u t s m o r f i s g n d n F i . 2 e l b a T i . s g n n a r t i m o r f s n o i t a u a v e l e v i t a t i l a u q e v i t i s o p d e v i e c e r . s e s s a l c e r u t s e g t n e r e ff d i . s r o t a c u d e . s e r u t s e g e r o t s d n a 1 1 f o t e s b u s a d e z i n g o c e r y l n o , d r o c e r , e r u t p a c o t s e c i v e d d e t s i s s a r e t u p m o c ) D s A ( r e d r o s i D i g n n r a e l d n a ) D l ( s e i t i l i b a s i D 5 - 2 d e g a ) 6 1 0 2 ( . l a t e n i e s a e r c n i % 4 4 a n i d e t l u s e r e s u r o t u t n a f o s s e n e v i t c e ff e d n a y t i l i b a e s u i e n m r e t e D s t n e m r i a p m i l a u s i V 4 1 - 4 d e g a n e r d l i h c 0 1 s u . l a t e y h t r a C c m . s n o i t c a r t n o c f o y r e t s a m i g n v o r p m i r o f r o t u t e l l i a r B d e s a b - t e n r e t n i ) i V ( 7 y b d e t c u r t s n i ) 6 1 0 2 ( s n o i t o m e e v i t i s o p d e w o h s s i s y l a n a . e s u g n i r u d l l a r e v o t u b l , t e b a t a g n i s u n e h w . s s e c o r p i g n h c a e t e h t g n i r u d s e c i v r e s n o i t a c u d e m u r t c e p s m s i t u A ) D s A ( r e d r o s i D y l l a i t i n i d e s u f n o c e r e w s t n e d u t s e m o s l a i c e p s d e e n o h w s t n e d u t s f o s d e e n i e n m r e t e D d n a e m o r d n y s n w o D . s n o i t c a r t n o c f o y r e t s a m ’ s t n e d u t s s r e h c a e t n e r d l i h c 3 s u r p y C . l a t e n a k y o s ) 7 1 0 2 ( t i h g u o h t l a , k r o w o t d e v e i l e b m e t s y s d n a s e r u t s e g e g a u g n a l n g i s s ’ r e ff e a h c s e s u m u r t c e p s m s i t u A n e r d l i h c f o p u o r g l l a m s i n a p s o s o n o D - z e m o G y h p a r g o h t r o l a i c fi i t r a n a c i s a b t h g e i d e n r a e l , i g n n a r t i i g n n a r t i d n u o s h c e e p s r e t t e l f o i n m 0 2 i n h t i W i A i n h t i w i g n n r a e l d n u o s h c e e p s - r e t t e l i e n m a x e y f i t n e d i o t l a i t n e t o p n o g n i s u c o f , s t p i r c s . i g n d a e r h t i w l e g g u r t s o h w s r e n r a e l ) d e u n i t n o C ( n r u t , n a p s n o i t n e t t a i , s r o v a h e b . s k s a t d e t s e t r e h t o d n a , g n i k a t e z a g l a i c o s n i t n e m e v o r p m i l l a r e v o . t o b o r e v i t s i s s a y l l a i c o s s u o m o n o t u a n a y b t u b n o i s s e r g e r t h g i l s g n i l a e v e r d e t c u d n o c s e m a g l a i c o s y l i a d h t i w n o i t n e v r e t n i . e c n e d n o p s e r r o c d n u o s h c e e p s - r e t t e l p u k c e h c y a d 0 6 a h t i w s y a d 0 3 r e v o s t n e m e v o r p m i e d a m n e r d l i h c 2 t u b l l A h t n o m - 1 e m o h - n i n a r e t f a D s A h t i w n e r d l i h c f o s l l i k s l a i c o s n i s t n e m e v o r p m i e t a r t s n o m e D ) D s A ( r e d r o s i D m u r t c e p s m s i t u A a i x e l s y D a i x e l s y d / w n e r d l i h c 2 7 s d n a l r e h t e n e h t . l a t e a n e v a r A a i x e l s y d o / w n e r d l i h c 6 4 ; n o i t a c fi i t n e d i 2 1 - 6 d e g a n e r d l i h c l l a ; x / a / o n i t a l s a d e fi i t n e d i n o i t a c fi i t n e d i 2 1 f o 4 ; s e i l i m a f 2 1 . l a t e i t a l l e s s a c s ) 8 1 0 2 ( ) 8 1 0 2 ( CoMpUTERS IN ThE SChoolS 7 s l i a u d v d n i i f o e s i t r e p x e t e y , l e b i s a e f . n o i t a i t i n i e y e e v o r p m i d d i n o i s s e s c i t o b o r e h t i d o n a m u h h t i w n o i t c a r e t n i r e h t e h w i e n m r e t e D . n o i t a i t i n i l a b r e v d n a t c a t n o c l a b r e v d n a t c a t n o c e y e d e v o r p m i t o b o r ) D s A ( r e d r o s i D m u r t c e p s m s i t u A 1 1 - 9 d e g a s t n e c s e o d a l 4 1 d e fi i c e p s n u ) 9 1 0 2 ( g n u h C n i e l i h w s n o i t o m e e v i t a g e n r e w e f n i d e t l u s e r e v a h y a m t C i f o e s u t u o h t i w n e r d l i h c d n a ) s D l ( s e i t i l i b a s i d i g n n r a e l . ) e l V ( s t n e m n o r i v n e i g n n r a e l l a u t r i v n i ) D l ( n e r d l i h c g n i k a e p s 1 1 - 7 d e g a ) 9 1 0 2 ( ; s n o i t o m e y n a m d e c n e i r e p x e n e r d l i h C h t i w n e r d l i h c f o s e t a t s l a n o i t o m e e r a p m o C s e i t i l i b a s i D i g n n r a e l c i b a r A e v i t a n 2 4 o c c o r o m . l a t e u o r r e h u o n i n o i t c e fl e r d n a i g n n o s a e r l a c i t i r c g n i s u e c n e g i l l e t n i l a t i g d i f o l e d o m A . s g n i t t e s l a t i g d i . e l V o t k n i l t s e g n o r t s d e w o h s m o d e r o B . d e fi i t n e d i e r e w D i h t i w s r e n r a e l r o f n o i t i n g o c e r e v i t c e ff a f o s e t a t s e e r h t . t n e m e v e h c a i i g n n r a e l . n o i t n e v r e t n i d e z i l a n o s r e p r o f n o i t a m r o f n i t n e m e g a g n e e m i t - l a e r h t i w s r e h c a e t i e d v o r p ) D i ( s e i t i l i b a s i D d n a d o l s r a e y 8 1 s r e h c a e t & , m o d g n K i d e t i n u y l a t i ) 0 2 0 2 ( l a u t c e l l e t n i o t 6 d e g a s t n e d u t s 7 6 , i n a p s : e p o r u e . l a t e n e d n a t s . e c n e g i l l e t n i l a t i g d i f o s t n e n o p m o c o / w d n a / w ) s r e h c a e t d n a , s t n e d u t s s n o i t a c fi i t n e d i y t i l i b a s i d ) 0 2 0 2 ( i n a m e h t f o t n e m p o e v e d l f o l e v e l y f i t n e d i s e i t i l i b a s i D l e p i t l u m , s t n e r a p ( s l i a u d v d n i i 5 4 a i s s u r . l a t e a v e i l v o o s l l a , s h t n o m x i s r e t f A . s n o s a e r t a s l l i k s r o t o m o h c y s p d n a t n e m p o e v e d l l a c i s y h p t n e r e ff d i r o f s e s s a l c e c n a d e v i s u l c n i e z y l a n a o t i g n n a r t i d e t r a t s s p u o r g h t o b m o r f s t n e d u t s n a i s e y a B n o d e s a b e c n a d e v i s u l c n i r o f k r o w t e n ) i m ( 9 1 - 7 1 ) 1 2 0 2 ( l e d o m g n n r a e i l l p o e v e D s t n e m r i a p m i y t i l i b o m d e g a s t n e c s e o d a l 0 3 i a n h C g n a W d n a u h . d e g a g n e y l e v i t c a s r e n r a e l . i g n n a r t i f o s e g a t s t n e r e ff d i t n e m u r t s n i 2 @ V t e n e l i b o m e h t g n i s u r e f s n a r t g n i s u i g n n r a e l p e e d f o y t i l i b a e t a u a v e l i g n n r a e l c fi i c e p s d e g a s t n e c s e o d a l 2 5 1 l e a r s i k c e d r a D & r o m . n o i t c e t e d D l s i g n d a i o t l o o t . D l s i g n n r a e l p e e d e v i t c e ff e e b o t d e g d u j y f i t n e d i o t l e d o m 2 V t e n e l i b o m d n a i g n n r a e l ) D l s ( s e i t i l i b a s i D 8 1 - 5 1 e v i t c i d e r p d e t a r o b o r r o c s t n e r a p . l i z a r B n i D i r o f n o i t n e v r e t n i y l r a e d n a , s i s o n g a d i ) D i ( s e i t i l i b a s i D 1 1 - 7 d e g a n e r d l i h c d n a s r o t a c u d e m o r f n o i t a m r o f n i , n o i t n e v e r p o t s s e c c a d n a p x e o t d e e n t e e m l a u t c e l l e t n i 8 5 7 1 , d n a s r e h c a e t 1 5 l i z a r B ) 1 2 0 2 ( ) 1 2 0 2 ( . l a t e a fl a t e b o t d e d e e n s l l i k s n o i t a c i n u m m o c a i g n d o c s a h c u s s n o i t c n u f m r o f r e p . t o b o r - n o i s i c e d e v i t a r t s i n m d a i ’ s r o t a c u d e l a i c e p s o t s m e t s y s t r e p x e g n i r a p m o C e b o t i d e n m r e t e d s a w g n i k a m . i n o n a p m o C i A l a u t r i v s r e g g i r t . t n e m u r t s n i i A f o y t i v i t i s n e s d n a l a i c o s i g n h c a e t n i d e d a i i C A t a h t s e c n a v d a l l a c i g o o n h c e t f o t c a p m i l e r o p x e ) D s A ( r e d r o s i D m u r t c e p s m s i t u A 2 1 - 5 d e g a n e r d l i h c 7 s u . l a t e s e h g u h ) 2 2 0 2 ( . d e n o i t s e u q s a w y d u t s n i . n o i s n e h e r p m o c a i x e l s y d / w d e fi i t n e d i d e v o r p m i e r u t c u r t s y r o t s d e t r o p p u s - i A . n o i s n e h e r p m o c i g n d a e r r o f t r o p p u s o t i A e s u a i x e l s y D , 3 1 d e g a s t n e c s e o d a l , 2 m o d g n K i d e t i n u ) 2 2 0 2 ( g n a Y i s g n d n F i ) s ( e s o p r u p h c r a e s e r ) s e i ( t i l i b a s i D s t n a p i c i t r a p s e t i s r a e Y & r o h t u A . d e u n i t n o C . 2 e l b a T 8 M. F. RICE AND S. DUNN disabilities (2 studies)—with some studies focused on dyslexia (2 studies) and 1 study focused on specific learning disabilities; visual impairments (1 studies), and multiple disabilities (6 studies). Other demographic characteristics Fourteen different countries were represented on five continents (Africa, Asia, Europe, and North and South America) for these studies. Ages of participating youth ranged from 3 to 19 years old. Participants reported speaking a variety of languages in their school settings, including English, Hebrew, Portuguese, Russian, Spanish, Arabic, Italian, and Dutch. Presence of parents and educators in the studies Parents or caregivers and educators that participated alongside researchers in these studies by providing data to researchers or participating in inter- vention processes. For example, Scassellati et al. (2018) worked with 12 families with children who had been identified with ASD to determine if a robot that modeled eye gaze, attention monitoring, and feedback would support children in acquiring this skill. In this study, parents participated alongside the children in these games. Also, some teachers participated by providing instruction to the students and reporting observations (Standen et al., 2020; Tafla et al., 2021; Yang, 2022). RQ 2: What are the stated intentions for supporting this population with AI? The patterns in research purpose were similar in the 19 articles examined when conducting research in AI. Researchers reported similar goals around four main themes: (1) supporting intellectual and emotional development; (2) saving time when collecting, evaluating, and communicating informa- tion and processes; (3) increasing the enjoyment of educational or inter- vention processes using AI; and (4) testing of an instrument for further use with children with varying disabilities. Although these themes emerged, there was some overlap. For example, two of the articles that addressed saving time were also focusing on improving the lives of those with dis- abilities (Gregg, 2009; Hu & Wang, 2021). Supporting intellectual, physical, and emotional development Ten of the articles discussed using AI to support the developmental pro- cesses of students with disabilities (Delavarian, 2015; Standen et al., 2020; Yang, 2022). They focused on intellectual improvements as well as physical, and emotional development. To illustrate, Hu and Wang (2021) focused on mobility challenges. They said that they wanted to study how AI could be used to aid teachers in supporting students with mobility issues in CoMpUTERS IN ThE SChoolS 9 learning to dance with peers of varying abilities. At the end of a six month study, researchers used AI algorithms to determine the level of improve- ments that were made. The researchers showed that the students’ overall physical health improved. As a result, Hu and Wang (2021) suggested conducting further research to gather additional evidence about how AI use with the physical aspect contributed to overall increases in emotional and spiritual well-being. Saving time for decision makers Three groups of researchers were interested in developing mechanisms to support educators in communicating information to all stakeholders who serve a child with a disability (Gomez-Donoso et al., 2016; Gregg, 2009). An example of such an instrument was the DDtrac that was discussed by Gregg (2009). Having such an instrument was proposed to aid schools in managing large amounts of data that is needed to provide various special education interventions. Having this type of tracking was also supposed to aid in monitoring specific behaviors and outcomes. Increasing the enjoyment of educational or intervention processes using AI Although several of the AI studies focus on improving the lives of children with disabilities, two emphasized student enjoyment as part of using AI software. For example, Zhang et al. (2009) study where they allowed students to practice social skills using avatars in both 2D and 3D Modes. While students were able to play online in an anonymous setting, they interacted with others and played in group and peer set- tings in the physical setting. A similar result was seen in a study con- ducted by Soykan et al. (2017) that highlighted how an AI software supported tablet use among students diagnosed with autism and down syndrome. Testing of an instrument for further use with children with varying disabilities AI requires precision testing of instruments that provide timely and accu- rate information to educators about issues such as early intervention and support for children with varying disabilities. One such instrument was the Mobile NetV2 deep CNN Architecture. According to Mor and Dardeck (2021), this instrument performed better than human beings in visual tasks. As a result, the instrument was used in the education setting to screen for specific learning disabilities using handwriting samples and a deep learning algorithm. Another author who presented results on instru- ments tested was Standen et al. (2020). These researchers demonstrated how AI tools might help in diagnosing specific disabilities and allow for 10 M. F. RICE AND S. DUNN early intervention. More information about the diagnostic uses is in a future section. RQ 3: What are findings of these studies about AI as a support for young people who have been identified with disabilities? The 19 studies found AI capable of providing: (1) emotional support, (2) communication skills (3) social support, (4) language and literacy support, and (5) support for identification and assessment. Emotional support Researchers argued that AI was a contributing factor to students’ emotional well-being. To demonstrate AI’s contribution to emotional satisfaction, Soykan et al. (2017) collected data about the emotions of five-year old children who had been identified with intellectual disabilities while they used tablets. The researchers indicated that although the children did not fully comprehend the material “according to the results of the artificial intelligence emotional analysis, it is seen that the students are happy and eager to learn…” (p. 1). Communication support AI was also found to facilitate communication, both verbal and non-verbal (Scassellati et al., 2018). Communication skills were taught with the ulti- mate intention of improving social skills by allowing students to practice in what was framed as an autonomous way. Another example of com- munication involved sign language. For example, Gomez-Donoso et al. (2016) studied how the Kinect v2 tool was used to aid children who had been identified with cognitive disabilities to communicate using sign language. While using this tool, children communicated with both human and robot companions. Although this tool only recognized 11 of the most popular varieties of sign languages, the tool was being developed to rec- ognize more of these while continuing to provide results that use a real- time sign-language recognition and classification system. Social skills support Zhang et al. (2009) demonstrated how learners that had been identified with language and learning disabilities used AI to learn appropriate social interactions using 2D and 3D avatars. While there was a stronger prefer- ence to using 3D avatars, the AI program allowed learners to be fully immersed in the learning experience, which may have contributed to the greater positive effect. In another study, Hughes et al. (2022), explored AI’s use in STEM programs in elementary schools. This research provided CoMpUTERS IN ThE SChoolS 11 positive results that AI supported learners with ASD who were needing to learn a variety of STEM related concepts while practicing communica- tion skills. Although the concepts of the virtual learning environment were first introduced using human companions, over time the program func- tioned effectively using Artificial Intelligent Companions (AIC) only to support the ASD learners in performing a variety of functions ranging from “learning basic coding, practicing their social skills with the AIC, and attaining emotional recognition and regulation skills for effective communication and learning” (Hughes et al., 2022, p. 1). Reading and language support Some studies identified in this review focused on AI and its use for stu- dents identified with dyslexia and other reading problems. When examining support services for students identified as having reading difficulties, the researchers found that AI technologies produced positive effects. Additionally, Wang et al. (2022) argued that Augmentative Alternative Communication (ACC) was as a vital communication tool for students with dyslexia and would further help students by providing an augmented reality (AR) for them. Support for identifying learners as having disabilities and assessing learners Researchers also claimed AI could be used to identify learners as having disabilities and assess learners. For assessing learning difficulties and iden- tifying children with disabilities, AI was used in three studies as part of the identification process. In a Brazilian study, Tafla et al. (2021) high- lighted the success of an AI algorithm with the Diagnosys framework in identifying students with characteristics associated with intellectual dis- abilities. From a sample size of 1758, AI accurately identified 22 students who were not previously diagnosed with these characteristics with an 85% accuracy rate. Aravena et al. (2018) also described success in using an artificial script to aid in determining the differences between dyslexic readers from nonreaders. The AI script feature enabled the assessors to determine the ability of both categories of students’ abilities to learn let- ter-speech sound correspondences more readily after having a brief training on how to use the AI technology. Hu and Wang (2021) used AI in dance education to work with children with mobility impairments, claiming also that the algorithm was less biased. Parry and Hofmeister (1986) reported similar results when the AI tool “Mandate Consultant” was tested against human experts. This tool gener- ated more consistent results based on its extensive stored knowledge base, although it should be noted that some researchers consider it controversial to use this technique because it generalizes treatments for children over 12 M. F. RICE AND S. DUNN time. In addition, Nanni and Lumini (2009) reported using the AI tool Ensemble to effectively identify 50% of students with learning disabilities with 100% confidence. Mor and Dardeck (2021) used a convolution neural network (CNN) as part of medical diagnosis with visual data. Mor and Dardeck (2021) also supposed that the CNN instrument could “potentially provide faster initial screening of students who may meet the criteria and hence improve their chances of receiving intervention” (p.161). RQ 4: How are disabilities framed and discussed in justifying the need for the AI support? The purpose of the last research question was to learn how disability as a concept was framed and discussed along with the individuals being identified as having them. This part of the analysis revealed (1) the researchers framed disability as a societal problem they were trying to solve; (2) the youth identified as having disabilities were framed as bur- densome and AI should lift this burden; (3) parents and teachers were largely described as individuals who would be relieved by AI of burdens of having to support children with disabilities, (4) the AI was described as a powerful savior. Disability is a ‘problem’ for researchers to solve with AI While it seems intuitive, even sensible that university-based researchers would be primary decision makers, it is worth noting that no methodologies or strategies used in any of the studies attempted to capture participants as co-designers. In addition to university-based researchers, some studies were collaborations with other researchers from government agencies (Avavena et al. 2018, Hughes et al., 2022; Tafla et al., 2021; Zhang et al., 2009). Additionally, there are several private organizations with claims to vested interests in AI tools and technologies. These companies also had researchers who were conducting studies on the use of AI (Zhang et al., 2009). Two of the 19 articles were written in partnerships with individuals from organizations other than the university setting. An example such a collaboration occurred in the article E-Drama: Facilitating Online Role- Play using an AI Actor and Emotionally Expressive Characters (Zang et al., 2009). It was co-written by one college professor and three other individ- uals from outside agencies. Three coauthors all represented different agen- cies, to include a charitable company. Researchers came from disciplines, including computer science, engineering, biomedical engineering, education, psychology, and information systems and AI. The researchers often nar- rated themselves and their work in extremely positive terms. For example, Zhang et al. (2009) wrote: CoMpUTERS IN ThE SChoolS 13 Our system creates a safe anonymous efficient learning environment, and it could also be used by young people with a learning disability and language impairment to engage in learning and interactions without fear of failure. (p. 7) During this statement of self-praise, the young people are positioned as having deficits—learning disabilities and language impairments as well as fears of failure—that the learning environment designed with AI by the researchers completely solves. Even though all the studies do mention limitations as a matter of protocol the extremely positive outlook about their work pervades the discourse for the 19 studies. Young people as ‘burden’ for AI to lift Young people in these 19 studies were largely positioned as needy and burdensome in this work. For example, Gregg (2009) wrote about the increasing numbers of students with developmental disabilities in schools, writing “Ddtrac makes it easier for special educators to better meet the needs of their special education students” (p. 460). The argument emerges that special educators are burdened by the students’ needs and the AI will at least partially relieve the burden. In addition to being positioned largely as burdens to be relieved, there was little evidence of collaboration with the young people to decide whether they wanted to be in the studies, to determine if they self-iden- tified as having the disabilities that qualified them for the study, or to learn what the young people thought should happen to the data they produced. There were also sometimes reductive statements without foun- dation or citation, such as in Chung (2019) where the researcher wrote, “Children with ASD like robots” (p. 430) as a statement of unequivocal fact. In another instance, Solovieva et al. (2021) wrote, “Digital technol- ogies significantly expand the boundaries of education for children who find it difficult to attend school due to their limitations” (p. 2) (emphasis added). The main framing for the need for AI and for the study, was that the children were deficient characters who needed an actor—AI—to help them. Parents and educators as would benefit from relief from AI Parents and educators were often described as the main beneficiaries of the relief AI was going to provide. For example, McCarthy et al. (2016) wrote of their study findings: The goal was never to teach braille contractions without a teacher of visually impaired students, but rather to augment the instruction provided and particularly to offer meaningful assistance when the teacher was not present. (p. 320) 14 M. F. RICE AND S. DUNN The statement instantiates the teacher as a needed entity—again bur- dened by the visually impaired students and the need to teach them to read with alternate means—with some utility in the work of supporting students who were using braille. Parents were often characterized as being disempowered or stressed with regards to their children. For example, Tafla et al. (2021) wrote that “Parents may recognize behaviors compatible with ID [intellectual disabil- ity], but deny them for fear, especially in cultures in which disabilities can be highly stigmatized” (p. 9). Such a statement extolls the need for an AI tool to diagnose the child properly and escape the bias of the parental fear. In fact, strong positive emotions were also used to argue for the need for the tools. Soykan et al. (2017) wrote: [S]tudents’ happiness and positive feelings during the process of using tablet comput- ers in education demonstrate the necessity of increasing the educational use of this kind of tool (p. 7). The use of negative emotions to some degree for teachers and to a large degree for the parents contrasts with the positive emotions of how much young people will enjoy the AI tools. This frown to smile framework for thinking about AI research results in a less powerful positioning for nearly everyone participating in these studies—except of course, the AI itself. AI as a powerful solution Ultimately, AI is the savior in these studies. AI comes to the rescue of parents and teachers to save them from the burdens associated with the care of a young person with some characteristics socially associated with a disability. Moreover, the AI is positioned as not having emotions or bias to navigate in addition to being a quick learner. For example, Aravena et al. (2018) wrote, “The findings indicate that after only 20 min of train- ing, the controls outperformed the dyslexic readers in identifying the newly learned letter-speech correspondences” (p. 553). In another example, Nor and Dardek (2021) wrote, “Outfitted with deep learning, mobile devices can assist with rapid screening of students with an SLD based on their handwriting” (p. 163) (emphasis added). In these instances, the AI receives praised for outperforming the very individuals it was supposedly remediating. Competition between AI and humans—in this case, a human already positioned in deficit regarding reading underscores the superiority of the AI and instantiates its place as being worthy of unqualified praise. In some cases, the AI’s superior abil- ities hedge on the extremely subtle suggestion that it is more human than an individual with a disability. Such was the case when Zhang et al. (2009) wrote, “Employing 3D expressive animation could also be very educational CoMpUTERS IN ThE SChoolS 15 for applications which teach autistic young people to learn emotional expression in non-verbal communication” (p.7). Such potential for the AI’s desirability over humans, especially humans with certain characteristics is highlighted in Chung’s (2019) statement, “humans are essentially alone in the world, [yet] they long to be connected with others” (p. 430), which was used to open the research space for a robot to teach social skills to children. In Scassellati et al.’s (2018) similar study with younger children, parents participated with the robot as well. Although researchers could have determined that the robot facilitated important parent-child interactions, the findings were presented as the unique contribution of the AI to skill development. In short, the AI con- sistently received more respect than humans in these studies. Discussion Findings from this review of 18 studies of AI as support for young people who have been identified as having disabilities highlight the state of research regarding this technology and the human population it purports to serve. Research in this area features individuals with varying demo- graphic characteristics and has covered a range of types of disabilities. Although purposes of these research studies seem sincere and findings of the studies positive, critique was offered for how young people, their parents or caregivers, and their teachers were positioned in this work. Contributions to theory These studies contribute to existing theories about AI in their framing as viable assistive supports in the educational setting. AI’s ability to learn quickly and to meet thresholds of accuracy seem positive, yet due to the vulnerability of young people who have been or might be identified as having disabilities it is important to understand the potential issues in essentially making AI a powerful decision making partner in discussions about how to identify and serve students when AI lacks legal standing as sentient entity and policies about AI are only emerging (Borenstein & Howard, 2021). While none of the researchers offered an explicit post-humanist view of the AI technology, the language used to describe AI framed it as the superior, sometimes even singular, actor with more power than others involved in the studies. This positioning emerged due to what appeared to be a belief in the speed, objectivity, and granular data learning and usage capacities of the AI systems (Fahimirad & Kotamjani, 2018; Vincent- Lancrin & Van der Vlies, 2020). While we accept that the AI might deserve a place to operate as an actor, we recommend caution regarding the stance of infallibility toward the AI, the opined universal appeal of it, and the 16 M. F. RICE AND S. DUNN elevation of AI as being more human and more worthy of praise than these children and adolescents who have been positioned as burdens with no power. The young people and their families seem to deserve a least as much awe as the technologies that are supposed to serve them. Contributions to practice and policy Pulling AI back into a reasonable orbit of credibility seems especially necessary in instances where there are debates and discrepancies about identification as having a disability and where chances to build an oppor- tunity structure might be denied based on having a disability (Rice & Ortiz, 2021). In countries like the U.S. where there is specific legislation about identification is mandated, the role of AI in the process of identi- fication might also have legal ramifications (IDEA, 2004). Parents and children are already outnumbered and outmaneuvered in meetings to make disability plans by school officials (Kurth et al., 2019). Therefore, caution should be taken to avoid positioning AI to further tip the balance in the institution’s favor. Researchers need to use their positions and expertise to ensure that what AI is offered as support to young people, truly oper- ates as support. This review highlighted various ways that parents and educators have participated in studies. While their crucial role as deliverers of support was generally acknowledged in the studies, there was also a positioning of these individuals as being under burden by the young people identified with disabilities. We suggest that if there is a burden to bear, it is the imposition of having to constantly adapt oneself and pressure for children to adapt to unsuitable educational and other social environments (Goodley et al., 2019; Marks, 1999; Sinclair, 2013). Researchers might consider other positionings for parents and teachers. For example, Rice & Oritz (2022) wrote about the relational tandem par- ents and children who had been identified as having disabilities formed and engaged in to do fully online learning in a way that made the demands of online school less burdensome. Specific positionings might include partnerships with the children, advocates for themselves and the young people, and/or intellectual contributors to the AI work. While we under- stand that for some, the goal of AI is to outperform humans, we propose that instead, AI educational innovation could be about empowering and serving the historically underserved and disempowered. Limitations and future research directions Limitations in literature reviews are typical in that research is constantly emerging and keywords may vary as technology changes. This literature CoMpUTERS IN ThE SChoolS 17 review did not cover engineering conferences, but perhaps future literature reviews should do so due to the fast-evolving nature of this area of research and the expertise available in key conferences such as the Institute of Electrical and Electronics Engineers. We also acknowledge the subjectivities involved in answering RQ4. However, Gilliard and Selwyn (2023) have cautioned about making engineers primary decision making actors in educational settings. Although there seemed to be a diverse representation of individuals demographically and geographically in these studies of AI support, young people who had been identified as having disabilities should play more active roles in research about support for them with AI. As such their range of acknowledge agencies was limited in these studies as is typical in many social settings (Dobusch, 2017; Lalvani & Broderick, 2013; Winzer, 1993). Researchers should find ways provide young people a wider frame for participation in work that is about them. This might involve more participatory methods and strategies for research alongside turns in dis- course regarding how disabilities are identified and framed. Also, the studies in this review mostly showed how the AI changed young people or identified them. There was little to no emphasis or discussion about how the young people changed the AI. This is an area where more research is needed. Future projects might consider the goals and aspirations that young people might have for themselves and their own understanding of their identities as having a disability or not (Dunn & Andrews, 2015). Even if AI tools might be considered more accurate than human raters, they could do damage through inhumane sorting, resulting in the social cleansing of undeniable behaviors and characteristics against the desires of the individual (Krügel et al., 2023). Such cautions might be crucial in diagnostic framings where the young people are given identities as having deficits or disabilities with AI that they may not desire as well as when AI might deny them an identity that they do desire. The focus of AI research in educational settings could shift from portraying young people as burdens that need to be relieved and instead focus on reliev- ing the burdens placed on young people by unsuitable, environments and communities. When theorizing about AI and its possibilities to support learning of the historically underserved, long histories of biases and exploitation must be considered as well (Chambers, 2020). Conclusion We revived studies of AI as support for young people identified as having disabilities describes a growing field of inquiry. While this growth holds 18 M. F. RICE AND S. DUNN the possibility for the empowerment of young people, researchers as nar- rators of position for this population should consider framing their work as an act of advocacy for young people instead of, or at least in addition to, AI technologies they are currently promoting. We look forward to the on-going possibilities in this field for disciplined, ethical participation and practice. Disclosure statement No potential conflict of interest was reported by the authors. ORCID Mary F. Rice Shernette Dunn http://orcid.org/0000-0002-8138-512X http://orcid.org/0000-0003-4191-4311 References *Analyzed in review of literature. *Aravena, S., Tijms, J., Snellings, P., & van der Molen, M. W. (2018). Predicting individual differences in reading and spelling skills with artificial script-based letter-speech sound training. Journal of Learning Disabilities, 51(6), 552–564. doi:10.1177/0022219417715407 Bal, M., & Lewin, J. E. (1983). The narrating and the focalizing: A theory of the agents in narrative. Style, 17(2), 234–269. Bal, M., & Van Boheemen, C. (2009). Narratology: Introduction to the theory of narrative. University of Toronto Press. Becker, B. (2017). Artificial intelligence in education: What is it, where is it now, where is it going? In B. Mooney (Ed.), Ireland’s yearbook of education 2017-2018 (pp. 42–46). Education Matters. Borenstein, J., & Howard, A. (2021). Emerging challenges in AI and the need for AI ethics education. AI and Ethics, 1(1), 61–65. doi:10.1007/s43681-020-00002-7 Brown, M., McCormack, M., Reeves, J., Brook, D. C., Grajek, S., Alexander, B., & Weber, N. (2020). 2020 Educause horizon report teaching and learning edition (pp. 2–58). EDUCAUSE. Catlin, D., & Blamires, M. (2019). Designing robots for special needs education. Technology, Knowledge and Learning, 24(2), 291–313. doi:10.1007/s10758-018-9378-8 Chambers, D. (2020). Assistive technology supporting inclusive education: Existing and emerging trends In Chambers D. (Ed.), Assistive technology to support inclusive educa- tion (pp. 1–17). Emerald. Chassignol, M., Khoroshavin, A., Klimova, A., & Bilyatdinova, A. (2018). intelligence trends in education: A narrative overview. Procedia Computer Science, 136, 16–24. doi:10.1016/j.procs.2018.08.233 *Chung, E. Y. H. (2019). Robotic intervention program for enhancement of social en- gagement among children with autism spectrum disorder. Journal of Developmental and Physical Disabilities, 31(4), 419–434. doi:10.1007/s10882-018-9651-8 Delavarian, M., Bokharaeian, B., Towhidkhah, F., & Gharibzadeh, S. (2015). Computer- based working memory training in children with mild intellectual disability. Early Child Development and Care, 185(1), 66–74. doi:10.1080/03004430.2014.903941 CoMpUTERS IN ThE SChoolS 19 Dobusch, L. (2017). Gender, dis‐/ability and diversity management: Unequal dynamics of inclusion? Gender, Work & Organization, 24(5), 487–505. doi:10.1111/gwao.12159 Dunn, D. S., & Andrews, E. E. (2015). Person-first and identity-first language: Developing psychologists’ cultural competence using disability language. The American Psychologist, 70(3), 255–264. doi:10.1037/a0038636 Edyburn, D. (2004). Rethinking assistive technology. Journal of Special Education Technology, 16(2), 516–525. doi:10.1177/001440291308000107 Edyburn, D. (2013). Critical issues in advancing the special education technology evidence base. Exceptional Children, 80(1), 7–24. doi:10.1177/001440291308000107 Fahimirad, M., & Kotamjani, S. S. (2018). A review on application of artificial intelligence in teaching and learning in educational contexts. International Journal of Learning and Development, 8(4), 106–118. doi:10.5296/ijld.v8i4.14057 Fairclough, N. (2003). Analyzing discourse: Text analysis for social research. Routledge. Gilliard, C., & Selwyn, N. (2023). Automated surveillance in education. Postdigital Science and Education, 5(1), 195–205. doi:10.1007/s42438-022-00295-3 *Gomez-Donoso, F., Cazorla, M., Garcia, A. G., & Garcia-Rodriguez, J. (2016). Automatic Schaeffer’s gestures recognition system. Expert Systems, 33(5), 480–488. doi:10.1111/ exsy.12160 Goodley, D., Lawthom, R., Liddiard, K., & Runswick-Cole, K. (2019). Provocations for critical disability studies. Disability & Society, 34(6), 972–997. doi:10.1080/09687599.2 019.1566889 *Gregg, D. (2009). Developing a collective intelligence application for special education. Decision Support Systems, 47(4), 455–465. doi:10.1016/j.dss.2009.04.012 Harré, R., & Moghaddam, F. M. (Eds.). (2003). The self and others: Positioning individ- uals and groups in personal, political, and cultural contexts. Greenwood Publishing Group. Higgins, J. P., Thomas, J., Chandler, J., Cumpston, M., Li, T., Page, M. J., & Welch, V. A. (Eds.). (2019). Cochrane handbook for support tools and mathematical reasoning. Contemporary Educational Technology, 7, 1–24. *Hu, M., & Wang, J. (2021). Artificial intelligence in dance education: Dance for students with special educational needs. Technology in Society, 67, 101784. doi:10.1016/j.tech- soc.2021.101784 *Hughes, C. E., Dieker, L. A., Glavey, E. M., Hines, R. A., Wilkins, I., Ingraham, K., Bukaty, C. A., Ali, K., Shah, S., Murphy, J., & Taylor, M. S. (2022). RAISE: Robotics & AI to improve STEM and social skills for elementary school students. Frontiers in Virtual Reality, 3, 968312. doi:10.3389/frvir.2022.968312 Individuals with Disabilities Education Act (IDEA), 20 U.S.C. § 1400 (2004). Karsenti, T. (2019). Artificial intelligence in education: The urgent need to prepare teachers for tomorrow’s schools. Formation et Profession, 27(1), 112–116. doi:10.18162/fp.2019.a167 Kenny, L., Hattersley, C., Molins, B., Buckley, C., Povey, C., & Pellicano, E. (2016). Which terms should be used to describe autism? Perspectives from the UK autism commu- nity. Autism : The International Journal of Research and Practice, 20(4), 442–462. doi:10.1177/1362361315588200 Krügel, S., Ostermaier, A., & Uhl, M. (2023). Algorithms as partners in crime: A lesson in ethics by design. Computers in Human Behavior, 138, 107483. doi:10.1016/j. chb.2022.107483 Kurth, J. A., McQueston, J. A., Ruppar, A. L., Toews, S. G., Johnston, R., & McCabe, K. M. (2019). A description of parent input in IEP development through analysis of IEP documents. Intellectual and Developmental Disabilities, 57(6), 485–498. doi:10.1352/1934- 9556-57.6.485 20 M. F. RICE AND S. DUNN Lalvani, P., & Broderick, A. A. (2013). Institutionalized ableism and the misguided “Disability Awareness Day”: Transformative pedagogies for teacher education. Equity & Excellence in Education, 46(4), 468–483. doi:10.1080/10665684.2013.838484 Luckin, R., Holmes, W., Griffiths, M., Forcier, L. B. (2016). Intelligence unleashed: An argument for AI in education. http://discovery.ucl.ac.uk/1475756/ McCarthy, T., Rosenblum, L. P., Johnson, B. G., Dittel, J., & Kearns, D. M. (2016). An artificial intelligence tutor: A supplementary tool for teaching and practicing braille. Journal of Visual Impairment & Blindness, 110(5), 309–322. doi:10.1177/014548 2X1611000503 McHugh, M. L. (2012). Interrater reliability: The kappa statistic. Biochemia Medica, 22(3), 276–282. doi:10.11613/BM.2012.031 Mertens, D. M., & Ginsberg, P. E. (2008). Deep in ethical waters: Transformative per- spectives for qualitative social work research. Qualitative Social Work, 7(4), 484–503. doi:10.1177/1473325008097142 *Mor, N., & Dardeck, K. (2021). Applying a conventional neural network to screen for specific learning disorder. Learning Disabilities: A Contemporary Journal, 19(2), 161. Moher, D., Liberati, A., Tetzlaff, J., & Altman, D. G. (2009). Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement. Annals of Internal Medicine, 151(4), 264–269. doi:10.7326/0003-4819-151-4-200908180-00135 *Nanni, L., & Lumini, A. (2009). Ensemble generation and feature selection for the iden- tification of students with learning disabilities. Expert Systems with Applications, 36(2), 3896–3900. doi:10.1016/j.eswa.2008.02.065 Ouherrou, N., Elhammoumi, O., Benmarrakchi, F., & El Kafi, J. (2019). Comparative study on emotions analysis from facial expressions in children with and without learning disabilities in virtual learning environment. Education and Information Technologies, 24(2), 1777–1792. doi:10.1007/s10639-018-09852-5 *Parry, J. D., & Hofmeister, A. M. (1986). Development and validation of an expert sys- tem for special educators. Learning Disability Quarterly, 9(2), 124–132. doi:10.2307/1510361 Popenici, S. A., & Kerr, S. (2017). Exploring the impact of artificial intelligence on teach- ing and learning in higher education. Research and Practice in Technology Enhanced Learning, 12(1), 22. doi:10.1186/s41039-017-0062-8 Rice, M., Ortiz, K., Curry, T., & Petropoulous, R. (2019). A case study of a foster parent working to support a child with multiple disabilities in a virtual school. Journal of Online Learning Research, 5(2), 145–158. https://www.learntechlib.org/p/184933/ Rice, M., & Ortiz, K. R. (2021). Parents’ use of technological literacies to support their children with disabilities in online learning environments. Online Learning, 25(3), 208–229. doi:10.24059/olj.v25i3.2407 Rice, M., & Ortiz, K. (2022). Parents of children with special educational needs’ shared work in fully online learning. Journal of Research on Technology in Education, 1–15. doi:10.1080/15391523.2022.2030269 Scassellati, B., Boccanfuso, L., Huang, C. M., Mademtzi, M., Qin, M., Salomons, N., Ventola, P., & Shic, F. (2018). Improving social skills in children with ASD using a long-term, in-home social robot. Science Robotics, 3(21). doi:10.1126/scirobotics.aat7544 Sinclair, J. (2013). Why I dislike “person first” language. Autonomy, the Critical Journal of Interdisciplinary Autism Studies, 1(2), 1. http://web.archive.org/web/20090210190652/ http://web.syr.edu/~jisincla/person_first.htm *Soykan, E., Ozdamli, F., & Ozcan, D. (2017). The emotional analysis of children with special needs during table usage in education. International Journal of Cognitive Research in Science, Engineering and Education, 5(2), 57–64. doi:10.5937/ijcrsee1702057S CoMpUTERS IN ThE SChoolS 21 *Standen, P. J., Brown, D. J., Taheri, M., Galvez Trigo, M. J., Boulton, H., Burton, A., Hallewell, M. J., Lathe, J. G., Shopland, N., Blanco Gonzalez, M. A., Kwiatkowska, G. M., Milli, E., Cobello, S., Mazzucato, A., Traversi, M., & Hortal, E. (2020). An evaluation of an adaptive learning system based on multimodal affect recognition for learners with intellectual dis- abilities. British Journal of Educational Technology, 51(5), 1748–1765. doi:10.1111/bjet.13010 *Tafla, T. L., Brunoni, D., Carreiro, L. R. R., Seabra, A. G., Silva, L. A. d., Bastos, D. C. d S., Rossi, A. C., Santos, P. H. A. d., & Teixeira, M. C. T. V. (2021). DIagnosys: An analytical framework for the identification of elementary school students with intellec- tual disability. Frontiers in Education, 6, 1–12. doi:10.3389/feduc.2021.609523 van Dijk, T. A. (1998). Ideology: A multidisciplinary approach. SAGE. Vincent-Lancrin, S., & Van der Vlies, R. (2020). Trustworthy artificial intelligence (AI) in education: Promises and challenges. OECD Education Working Papers. https://www. oecd-ilibrary.org/content/paper/a6c90fa9-en Wodak, R. & Meyer, M. (Eds.) (2016). Methods of critical discourse studies. SAGE. *Yang, H. (2022). Effect of story structure instruction based on visual analysis on reading comprehension intervention for dyslexic students. Computational Intelligence and Neuroscience, 2022 (2022)., 9479709. doi:10.1155/2022/9479709 *Zhang, L., Gillies, M., Dhaliwal, K., Gower, A., Robertson, D., & Crabtree, B. (2009). E-Drama: Facilitating online role-play using an AI actor and emotionally expressive characters. International Journal of Artificial Intelligence in Education, 19, 5–38.